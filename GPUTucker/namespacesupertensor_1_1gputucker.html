<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>GPUTucker: supertensor::gputucker Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">GPUTucker
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('namespacesupertensor_1_1gputucker.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">supertensor::gputucker Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacesupertensor_1_1gputucker_1_1constants"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker_1_1constants.html">constants</a></td></tr>
<tr class="memdesc:namespacesupertensor_1_1gputucker_1_1constants"><td class="mdescLeft">&#160;</td><td class="mdescRight">Contains constant values used in the Tucker decomposition algorithm. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespacesupertensor_1_1gputucker_1_1enums"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker_1_1enums.html">enums</a></td></tr>
<tr class="memdesc:namespacesupertensor_1_1gputucker_1_1enums"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enumerations used in the Tucker decomposition algorithm. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_block.html">Block</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A class representing a block in the Tucker decomposition.  <a href="classsupertensor_1_1gputucker_1_1_block.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_command_line_options.html">CommandLineOptions</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Command line options for the Tucker decomposition program.  <a href="classsupertensor_1_1gputucker_1_1_command_line_options.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_cuda_agent.html">CudaAgent</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA agent class for managing CUDA resources in Tucker decomposition.  <a href="classsupertensor_1_1gputucker_1_1_cuda_agent.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_optimizer.html">Optimizer</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classsupertensor_1_1gputucker_1_1_optimizer.html" title="Optimizer class for Tucker decomposition.">Optimizer</a> class for Tucker decomposition.  <a href="classsupertensor_1_1gputucker_1_1_optimizer.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_scheduler.html">Scheduler</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classsupertensor_1_1gputucker_1_1_scheduler.html" title="Scheduler class for Tucker decomposition.">Scheduler</a> class for Tucker decomposition.  <a href="classsupertensor_1_1gputucker_1_1_scheduler.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_tensor.html">Tensor</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classsupertensor_1_1gputucker_1_1_tensor.html" title="Tensor class for Tucker decomposition.">Tensor</a> class for Tucker decomposition.  <a href="classsupertensor_1_1gputucker_1_1_tensor.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsupertensor_1_1gputucker_1_1_tensor_manager.html">TensorManager</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classsupertensor_1_1gputucker_1_1_tensor.html" title="Tensor class for Tucker decomposition.">Tensor</a> manager class for Tucker decomposition.  <a href="classsupertensor_1_1gputucker_1_1_tensor_manager.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a9c72352f3852f79670db2b325de668b7"><td class="memTemplParams" colspan="2">template&lt;typename IndexType , typename ValueType &gt; </td></tr>
<tr class="memitem:a9c72352f3852f79670db2b325de668b7"><td class="memTemplItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a9c72352f3852f79670db2b325de668b7">computing_delta_kernel</a> (std::uintptr_t *X_indices, ValueType *X_values, std::uintptr_t *core_indices, ValueType *core_values, ValueType *delta, std::uintptr_t *factors, const int order, const int rank, int curr_factor_id, uint64_t nnz_count, uint64_t core_nnz_count)</td></tr>
<tr class="memdesc:a9c72352f3852f79670db2b325de668b7"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA kernel function for computing delta in Tucker decomposition.  <a href="namespacesupertensor_1_1gputucker.html#a9c72352f3852f79670db2b325de668b7">More...</a><br /></td></tr>
<tr class="separator:a9c72352f3852f79670db2b325de668b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68a2c59560c46c9aad94d3604c1bfdd6"><td class="memTemplParams" colspan="2">template&lt;typename TensorType , typename MatrixType , typename DeltaType , typename CudaAgentType , typename SchedulerType &gt; </td></tr>
<tr class="memitem:a68a2c59560c46c9aad94d3604c1bfdd6"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a68a2c59560c46c9aad94d3604c1bfdd6">ComputingDelta</a> (TensorType *tensor, TensorType *core_tensor, MatrixType ***factor_matrices, DeltaType **delta, int curr_factor_id, int rank, CudaAgentType *cuda_agent, SchedulerType *scheduler, int device_id)</td></tr>
<tr class="memdesc:a68a2c59560c46c9aad94d3604c1bfdd6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes delta values for Tucker decomposition.  <a href="namespacesupertensor_1_1gputucker.html#a68a2c59560c46c9aad94d3604c1bfdd6">More...</a><br /></td></tr>
<tr class="separator:a68a2c59560c46c9aad94d3604c1bfdd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a610a8159f773514d69cfe06ed0486501"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a610a8159f773514d69cfe06ed0486501">PrintLine</a> ()</td></tr>
<tr class="separator:a610a8159f773514d69cfe06ed0486501"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa063934e27b2a4d74b34aaa283d3abd4"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#aa063934e27b2a4d74b34aaa283d3abd4">make_error_log</a> (std::string msg, char const *file, char const *function, std::size_t line)</td></tr>
<tr class="memdesc:aa063934e27b2a4d74b34aaa283d3abd4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generates an error log message with file, function, and line details.  <a href="namespacesupertensor_1_1gputucker.html#aa063934e27b2a4d74b34aaa283d3abd4">More...</a><br /></td></tr>
<tr class="separator:aa063934e27b2a4d74b34aaa283d3abd4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b90544c94c3b6d91bcc202ba75e178c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a6b90544c94c3b6d91bcc202ba75e178c"><td class="memTemplItemLeft" align="right" valign="top">T *&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a6b90544c94c3b6d91bcc202ba75e178c">allocate</a> (size_t num)</td></tr>
<tr class="memdesc:a6b90544c94c3b6d91bcc202ba75e178c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Allocates memory for a given type.  <a href="namespacesupertensor_1_1gputucker.html#a6b90544c94c3b6d91bcc202ba75e178c">More...</a><br /></td></tr>
<tr class="separator:a6b90544c94c3b6d91bcc202ba75e178c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4491b1e4b98adfd17bbfd3c636af9b65"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a4491b1e4b98adfd17bbfd3c636af9b65"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a4491b1e4b98adfd17bbfd3c636af9b65">deallocate</a> (T *ptr)</td></tr>
<tr class="memdesc:a4491b1e4b98adfd17bbfd3c636af9b65"><td class="mdescLeft">&#160;</td><td class="mdescRight">Deallocates memory.  <a href="namespacesupertensor_1_1gputucker.html#a4491b1e4b98adfd17bbfd3c636af9b65">More...</a><br /></td></tr>
<tr class="separator:a4491b1e4b98adfd17bbfd3c636af9b65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af96c4ba3d0effc0d954b0db329d80f4d"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:af96c4ba3d0effc0d954b0db329d80f4d"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#af96c4ba3d0effc0d954b0db329d80f4d">frand</a> (T x, T y)</td></tr>
<tr class="memdesc:af96c4ba3d0effc0d954b0db329d80f4d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generates a random value within a specified range.  <a href="namespacesupertensor_1_1gputucker.html#af96c4ba3d0effc0d954b0db329d80f4d">More...</a><br /></td></tr>
<tr class="separator:af96c4ba3d0effc0d954b0db329d80f4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2172c2d1171da323fe6c968be66a761"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ab2172c2d1171da323fe6c968be66a761"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#ab2172c2d1171da323fe6c968be66a761">abs</a> (T x)</td></tr>
<tr class="memdesc:ab2172c2d1171da323fe6c968be66a761"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the absolute value of a number.  <a href="namespacesupertensor_1_1gputucker.html#ab2172c2d1171da323fe6c968be66a761">More...</a><br /></td></tr>
<tr class="separator:ab2172c2d1171da323fe6c968be66a761"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a811eaff5219b14bf771d6d37f96b7a72"><td class="memItemLeft" align="right" valign="top">const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a811eaff5219b14bf771d6d37f96b7a72">_cuda_get_error_enum</a> (cudaError_t err)</td></tr>
<tr class="separator:a811eaff5219b14bf771d6d37f96b7a72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b7039e3a1338692cc23b5d659129f16"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a2b7039e3a1338692cc23b5d659129f16">_cuda_check</a> (cudaError_t result, char *const func, const char *const file, int const line)</td></tr>
<tr class="memdesc:a2b7039e3a1338692cc23b5d659129f16"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks the result of a CUDA API call.  <a href="namespacesupertensor_1_1gputucker.html#a2b7039e3a1338692cc23b5d659129f16">More...</a><br /></td></tr>
<tr class="separator:a2b7039e3a1338692cc23b5d659129f16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a153469886ab0ff1f195f1e8bffd54ac4"><td class="memTemplParams" colspan="2">template&lt;typename IndexType , typename ValueType &gt; </td></tr>
<tr class="memitem:a153469886ab0ff1f195f1e8bffd54ac4"><td class="memTemplItemLeft" align="right" valign="top">__global__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a153469886ab0ff1f195f1e8bffd54ac4">ComputingReconstructionKernel</a> (std::uintptr_t *X_indices, std::uintptr_t *core_indices, ValueType *core_values, ValueType *error_T, std::uintptr_t *factors, const int order, const int rank, uint64_t nnz_count, uint64_t core_nnz_count)</td></tr>
<tr class="memdesc:a153469886ab0ff1f195f1e8bffd54ac4"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA kernel for computing the reconstruction error in Tucker decomposition.  <a href="namespacesupertensor_1_1gputucker.html#a153469886ab0ff1f195f1e8bffd54ac4">More...</a><br /></td></tr>
<tr class="separator:a153469886ab0ff1f195f1e8bffd54ac4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adee505ada92e53f708d75a31e30f241d"><td class="memTemplParams" colspan="2">template&lt;typename TensorType , typename MatrixType , typename ErrorType , typename CudaAgentType , typename SchedulerType &gt; </td></tr>
<tr class="memitem:adee505ada92e53f708d75a31e30f241d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#adee505ada92e53f708d75a31e30f241d">ComputingReconstruction</a> (TensorType *tensor, TensorType *core_tensor, MatrixType ***factor_matrices, ErrorType **error_T, int rank, CudaAgentType *cuda_agent, SchedulerType *scheduler, int device_id)</td></tr>
<tr class="memdesc:adee505ada92e53f708d75a31e30f241d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the reconstruction error for each block of the tensor.  <a href="namespacesupertensor_1_1gputucker.html#adee505ada92e53f708d75a31e30f241d">More...</a><br /></td></tr>
<tr class="separator:adee505ada92e53f708d75a31e30f241d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35acd9caa065829bb784df3b6a1ba196"><td class="memTemplParams" colspan="2">template&lt;typename TensorType , typename MatrixType , typename ErrorType , typename CudaAgentType , typename SchedulerType &gt; </td></tr>
<tr class="memitem:a35acd9caa065829bb784df3b6a1ba196"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a35acd9caa065829bb784df3b6a1ba196">Reconstruction</a> (TensorType *tensor, TensorType *core_tensor, MatrixType ***factor_matrices, double *fit, ErrorType **error_T, int rank, int device_count, CudaAgentType **cuda_agents, SchedulerType *scheduler)</td></tr>
<tr class="memdesc:a35acd9caa065829bb784df3b6a1ba196"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the reconstruction error and fit value for Tucker decomposition.  <a href="namespacesupertensor_1_1gputucker.html#a35acd9caa065829bb784df3b6a1ba196">More...</a><br /></td></tr>
<tr class="separator:a35acd9caa065829bb784df3b6a1ba196"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1921d1d3aba84f518893f68814bca4ac"><td class="memTemplParams" colspan="2">template&lt;typename TensorType , typename OptimizerType , typename CudaAgentType , typename SchedulerType &gt; </td></tr>
<tr class="memitem:a1921d1d3aba84f518893f68814bca4ac"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a1921d1d3aba84f518893f68814bca4ac">TuckerDecomposition</a> (TensorType *tensor, OptimizerType *optimizer, CudaAgentType **cuda_agents, SchedulerType *scheduler)</td></tr>
<tr class="memdesc:a1921d1d3aba84f518893f68814bca4ac"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs Tucker decomposition on a tensor.  <a href="namespacesupertensor_1_1gputucker.html#a1921d1d3aba84f518893f68814bca4ac">More...</a><br /></td></tr>
<tr class="separator:a1921d1d3aba84f518893f68814bca4ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7519edd69d7a0fca17fc1f74a3baa681"><td class="memTemplParams" colspan="2">template&lt;typename TensorType , typename MatrixType , typename DeltaType &gt; </td></tr>
<tr class="memitem:a7519edd69d7a0fca17fc1f74a3baa681"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#a7519edd69d7a0fca17fc1f74a3baa681">ComputingBC</a> (TensorType *tensor, DeltaType **delta, MatrixType **B, MatrixType **C, int curr_factor_id, int rank)</td></tr>
<tr class="memdesc:a7519edd69d7a0fca17fc1f74a3baa681"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes matrix B and vector C for factor matrix update.  <a href="namespacesupertensor_1_1gputucker.html#a7519edd69d7a0fca17fc1f74a3baa681">More...</a><br /></td></tr>
<tr class="separator:a7519edd69d7a0fca17fc1f74a3baa681"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8daca273725962464a8cd6bd421f683"><td class="memTemplParams" colspan="2">template&lt;typename TensorType , typename MatrixType , typename ValueType , typename CudaAgentType , typename SchedulerType &gt; </td></tr>
<tr class="memitem:ae8daca273725962464a8cd6bd421f683"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacesupertensor_1_1gputucker.html#ae8daca273725962464a8cd6bd421f683">UpdateFactorMatrices</a> (TensorType *tensor, TensorType *core_tensor, ValueType ***factor_matrices, ValueType **delta, MatrixType **B, MatrixType **C, int rank, int device_count, CudaAgentType **cuda_agents, SchedulerType *scheduler)</td></tr>
<tr class="memdesc:ae8daca273725962464a8cd6bd421f683"><td class="mdescLeft">&#160;</td><td class="mdescRight">Updates the factor matrices in Tucker decomposition.  <a href="namespacesupertensor_1_1gputucker.html#ae8daca273725962464a8cd6bd421f683">More...</a><br /></td></tr>
<tr class="separator:ae8daca273725962464a8cd6bd421f683"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a2b7039e3a1338692cc23b5d659129f16"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b7039e3a1338692cc23b5d659129f16">&#9670;&nbsp;</a></span>_cuda_check()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::_cuda_check </td>
          <td>(</td>
          <td class="paramtype">cudaError_t&#160;</td>
          <td class="paramname"><em>result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *const&#160;</td>
          <td class="paramname"><em>func</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const char *const&#160;</td>
          <td class="paramname"><em>file</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int const&#160;</td>
          <td class="paramname"><em>line</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks the result of a CUDA API call. </p>
<p>This function checks the result of a CUDA API call and prints an error message if the call failed. It also resets the CUDA device and exits the program.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">result</td><td>The CUDA error code returned by the API call. </td></tr>
    <tr><td class="paramname">func</td><td>The name of the function where the error occurred. </td></tr>
    <tr><td class="paramname">file</td><td>The name of the file where the error occurred. </td></tr>
    <tr><td class="paramname">line</td><td>The line number where the error occurred. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a811eaff5219b14bf771d6d37f96b7a72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a811eaff5219b14bf771d6d37f96b7a72">&#9670;&nbsp;</a></span>_cuda_get_error_enum()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const char* supertensor::gputucker::_cuda_get_error_enum </td>
          <td>(</td>
          <td class="paramtype">cudaError_t&#160;</td>
          <td class="paramname"><em>err</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ab2172c2d1171da323fe6c968be66a761"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2172c2d1171da323fe6c968be66a761">&#9670;&nbsp;</a></span>abs()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T supertensor::gputucker::abs </td>
          <td>(</td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the absolute value of a number. </p>
<p>Computes the absolute value of a given number <code>x</code>.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type of the number. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The number whose absolute value is to be calculated. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The absolute value of <code>x</code>. </dd></dl>

</div>
</div>
<a id="a6b90544c94c3b6d91bcc202ba75e178c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b90544c94c3b6d91bcc202ba75e178c">&#9670;&nbsp;</a></span>allocate()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T* supertensor::gputucker::allocate </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Allocates memory for a given type. </p>
<p>Allocates memory for an array of elements of type <code>T</code>.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type of the elements. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">num</td><td>The number of elements to allocate. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A pointer to the allocated memory. </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>if memory allocation fails. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9c72352f3852f79670db2b325de668b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c72352f3852f79670db2b325de668b7">&#9670;&nbsp;</a></span>computing_delta_kernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename IndexType , typename ValueType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__global__ void supertensor::gputucker::computing_delta_kernel </td>
          <td>(</td>
          <td class="paramtype">std::uintptr_t *&#160;</td>
          <td class="paramname"><em>X_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType *&#160;</td>
          <td class="paramname"><em>X_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::uintptr_t *&#160;</td>
          <td class="paramname"><em>core_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType *&#160;</td>
          <td class="paramname"><em>core_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType *&#160;</td>
          <td class="paramname"><em>delta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::uintptr_t *&#160;</td>
          <td class="paramname"><em>factors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>order</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>curr_factor_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint64_t&#160;</td>
          <td class="paramname"><em>nnz_count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint64_t&#160;</td>
          <td class="paramname"><em>core_nnz_count</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>CUDA kernel function for computing delta in Tucker decomposition. </p>
<p>This CUDA kernel function computes the delta values used in Tucker decomposition. The delta values are calculated based on the input tensor, core tensor, and factor matrices.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">IndexType</td><td>The data type used for indices. </td></tr>
    <tr><td class="paramname">ValueType</td><td>The data type used for values. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X_indices</td><td>The indices of the input tensor. </td></tr>
    <tr><td class="paramname">X_values</td><td>The values of the input tensor. </td></tr>
    <tr><td class="paramname">core_indices</td><td>The indices of the core tensor. </td></tr>
    <tr><td class="paramname">core_values</td><td>The values of the core tensor. </td></tr>
    <tr><td class="paramname">delta</td><td>Array to store the computed delta values. </td></tr>
    <tr><td class="paramname">factors</td><td>The factor matrices used in decomposition. </td></tr>
    <tr><td class="paramname">order</td><td>The order (dimension) of the tensor. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
    <tr><td class="paramname">curr_factor_id</td><td>The ID of the current factor matrix. </td></tr>
    <tr><td class="paramname">nnz_count</td><td>The number of non-zero elements in the input tensor. </td></tr>
    <tr><td class="paramname">core_nnz_count</td><td>The number of non-zero elements in the core tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7519edd69d7a0fca17fc1f74a3baa681"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7519edd69d7a0fca17fc1f74a3baa681">&#9670;&nbsp;</a></span>ComputingBC()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TensorType , typename MatrixType , typename DeltaType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::ComputingBC </td>
          <td>(</td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">DeltaType **&#160;</td>
          <td class="paramname"><em>delta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType **&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType **&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>curr_factor_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes matrix B and vector C for factor matrix update. </p>
<p>This function computes the matrix B and vector C needed to update the factor matrices in the Tucker decomposition. The computation is performed for the specified factor matrix identified by <code>curr_factor_id</code>.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TensorType</td><td>The type of the tensor being decomposed. </td></tr>
    <tr><td class="paramname">MatrixType</td><td>The type used for matrices in the decomposition. </td></tr>
    <tr><td class="paramname">DeltaType</td><td>The type used for delta values in the decomposition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Pointer to the input tensor. </td></tr>
    <tr><td class="paramname">delta</td><td>Array of delta values used in the decomposition. </td></tr>
    <tr><td class="paramname">B</td><td>Array of matrices B to be computed. </td></tr>
    <tr><td class="paramname">C</td><td>Array of vectors C to be computed. </td></tr>
    <tr><td class="paramname">curr_factor_id</td><td>The ID of the current factor matrix being updated. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a68a2c59560c46c9aad94d3604c1bfdd6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68a2c59560c46c9aad94d3604c1bfdd6">&#9670;&nbsp;</a></span>ComputingDelta()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TensorType , typename MatrixType , typename DeltaType , typename CudaAgentType , typename SchedulerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::ComputingDelta </td>
          <td>(</td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>core_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType ***&#160;</td>
          <td class="paramname"><em>factor_matrices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">DeltaType **&#160;</td>
          <td class="paramname"><em>delta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>curr_factor_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">CudaAgentType *&#160;</td>
          <td class="paramname"><em>cuda_agent</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">SchedulerType *&#160;</td>
          <td class="paramname"><em>scheduler</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>device_id</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes delta values for Tucker decomposition. </p>
<p>This function orchestrates the computation of delta values for Tucker decomposition by setting up the necessary GPU memory, launching the CUDA kernel, and managing memory transfers between host and device.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TensorType</td><td>The type of the tensor. </td></tr>
    <tr><td class="paramname">MatrixType</td><td>The type of the factor matrices. </td></tr>
    <tr><td class="paramname">DeltaType</td><td>The type used for delta values. </td></tr>
    <tr><td class="paramname">CudaAgentType</td><td>The type of the CUDA agent. </td></tr>
    <tr><td class="paramname">SchedulerType</td><td>The type of the scheduler. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">core_tensor</td><td>The core tensor. </td></tr>
    <tr><td class="paramname">factor_matrices</td><td>The factor matrices used in decomposition. </td></tr>
    <tr><td class="paramname">delta</td><td>Array to store the computed delta values. </td></tr>
    <tr><td class="paramname">curr_factor_id</td><td>The ID of the current factor matrix. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
    <tr><td class="paramname">cuda_agent</td><td>Pointer to the CUDA agent managing device resources. </td></tr>
    <tr><td class="paramname">scheduler</td><td>Pointer to the scheduler managing computational tasks. </td></tr>
    <tr><td class="paramname">device_id</td><td>The ID of the CUDA device to be used. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="adee505ada92e53f708d75a31e30f241d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adee505ada92e53f708d75a31e30f241d">&#9670;&nbsp;</a></span>ComputingReconstruction()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TensorType , typename MatrixType , typename ErrorType , typename CudaAgentType , typename SchedulerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::ComputingReconstruction </td>
          <td>(</td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>core_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType ***&#160;</td>
          <td class="paramname"><em>factor_matrices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ErrorType **&#160;</td>
          <td class="paramname"><em>error_T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">CudaAgentType *&#160;</td>
          <td class="paramname"><em>cuda_agent</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">SchedulerType *&#160;</td>
          <td class="paramname"><em>scheduler</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>device_id</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the reconstruction error for each block of the tensor. </p>
<p>This function computes the reconstruction error for each block of the tensor by launching the CUDA kernel <code>ComputingReconstructionKernel</code>. It manages the necessary memory transfers between host and device, and coordinates the computation across multiple CUDA streams.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TensorType</td><td>The type of the tensor. </td></tr>
    <tr><td class="paramname">MatrixType</td><td>The type of the factor matrices. </td></tr>
    <tr><td class="paramname">ErrorType</td><td>The type used for error values. </td></tr>
    <tr><td class="paramname">CudaAgentType</td><td>The type of the CUDA agent. </td></tr>
    <tr><td class="paramname">SchedulerType</td><td>The type of the scheduler. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">core_tensor</td><td>The core tensor. </td></tr>
    <tr><td class="paramname">factor_matrices</td><td>The factor matrices used in decomposition. </td></tr>
    <tr><td class="paramname">error_T</td><td>The array to store the reconstruction error. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
    <tr><td class="paramname">cuda_agent</td><td>The CUDA agent managing device resources. </td></tr>
    <tr><td class="paramname">scheduler</td><td>The scheduler managing computational tasks. </td></tr>
    <tr><td class="paramname">device_id</td><td>The ID of the CUDA device to be used. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a153469886ab0ff1f195f1e8bffd54ac4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a153469886ab0ff1f195f1e8bffd54ac4">&#9670;&nbsp;</a></span>ComputingReconstructionKernel()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename IndexType , typename ValueType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__global__ void supertensor::gputucker::ComputingReconstructionKernel </td>
          <td>(</td>
          <td class="paramtype">std::uintptr_t *&#160;</td>
          <td class="paramname"><em>X_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::uintptr_t *&#160;</td>
          <td class="paramname"><em>core_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType *&#160;</td>
          <td class="paramname"><em>core_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType *&#160;</td>
          <td class="paramname"><em>error_T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::uintptr_t *&#160;</td>
          <td class="paramname"><em>factors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>order</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint64_t&#160;</td>
          <td class="paramname"><em>nnz_count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint64_t&#160;</td>
          <td class="paramname"><em>core_nnz_count</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>CUDA kernel for computing the reconstruction error in Tucker decomposition. </p>
<p>This kernel computes the reconstruction error for each block of the tensor during Tucker decomposition. The error is calculated based on the difference between the original tensor values and the values reconstructed from the core tensor and factor matrices.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">IndexType</td><td>The data type used for indices. </td></tr>
    <tr><td class="paramname">ValueType</td><td>The data type used for values. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X_indices</td><td>The indices of the input tensor. </td></tr>
    <tr><td class="paramname">core_indices</td><td>The indices of the core tensor. </td></tr>
    <tr><td class="paramname">core_values</td><td>The values of the core tensor. </td></tr>
    <tr><td class="paramname">error_T</td><td>The array to store the reconstruction error. </td></tr>
    <tr><td class="paramname">factors</td><td>The factor matrices used in decomposition. </td></tr>
    <tr><td class="paramname">order</td><td>The order (rank) of the tensor. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
    <tr><td class="paramname">nnz_count</td><td>The number of non-zero elements in the input tensor. </td></tr>
    <tr><td class="paramname">core_nnz_count</td><td>The number of non-zero elements in the core tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4491b1e4b98adfd17bbfd3c636af9b65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4491b1e4b98adfd17bbfd3c636af9b65">&#9670;&nbsp;</a></span>deallocate()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::deallocate </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>ptr</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Deallocates memory. </p>
<p>Frees the memory allocated for the given pointer.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type of the pointer. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ptr</td><td>The pointer to the memory to deallocate. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af96c4ba3d0effc0d954b0db329d80f4d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af96c4ba3d0effc0d954b0db329d80f4d">&#9670;&nbsp;</a></span>frand()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T supertensor::gputucker::frand </td>
          <td>(</td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Generates a random value within a specified range. </p>
<p>Generates a random value between <code>x</code> and <code>y</code> of type <code>T</code>.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type of the random value. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>The lower bound of the range. </td></tr>
    <tr><td class="paramname">y</td><td>The upper bound of the range. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A random value between <code>x</code> and <code>y</code>. </dd></dl>

</div>
</div>
<a id="aa063934e27b2a4d74b34aaa283d3abd4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa063934e27b2a4d74b34aaa283d3abd4">&#9670;&nbsp;</a></span>make_error_log()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string supertensor::gputucker::make_error_log </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>msg</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char const *&#160;</td>
          <td class="paramname"><em>file</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char const *&#160;</td>
          <td class="paramname"><em>function</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>line</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Generates an error log message with file, function, and line details. </p>
<p>This function creates a formatted error message that includes the file name, function name, and line number where the error occurred.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">msg</td><td>The error message. </td></tr>
    <tr><td class="paramname">file</td><td>The file name where the error occurred. </td></tr>
    <tr><td class="paramname">function</td><td>The function name where the error occurred. </td></tr>
    <tr><td class="paramname">line</td><td>The line number where the error occurred. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A formatted error message string. </dd></dl>

</div>
</div>
<a id="a610a8159f773514d69cfe06ed0486501"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a610a8159f773514d69cfe06ed0486501">&#9670;&nbsp;</a></span>PrintLine()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::PrintLine </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a35acd9caa065829bb784df3b6a1ba196"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35acd9caa065829bb784df3b6a1ba196">&#9670;&nbsp;</a></span>Reconstruction()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TensorType , typename MatrixType , typename ErrorType , typename CudaAgentType , typename SchedulerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::Reconstruction </td>
          <td>(</td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>core_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType ***&#160;</td>
          <td class="paramname"><em>factor_matrices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>fit</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ErrorType **&#160;</td>
          <td class="paramname"><em>error_T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>device_count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">CudaAgentType **&#160;</td>
          <td class="paramname"><em>cuda_agents</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">SchedulerType *&#160;</td>
          <td class="paramname"><em>scheduler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes the reconstruction error and fit value for Tucker decomposition. </p>
<p>This function computes the reconstruction error for each block of the tensor by using the CUDA-enabled reconstruction computation and then calculates the overall fit value based on the total error and the norm of the original tensor. The function operates in parallel across multiple CUDA devices.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TensorType</td><td>The type of the tensor. </td></tr>
    <tr><td class="paramname">MatrixType</td><td>The type of the factor matrices. </td></tr>
    <tr><td class="paramname">ErrorType</td><td>The type used for error values. </td></tr>
    <tr><td class="paramname">CudaAgentType</td><td>The type of the CUDA agent. </td></tr>
    <tr><td class="paramname">SchedulerType</td><td>The type of the scheduler. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">core_tensor</td><td>The core tensor resulting from Tucker decomposition. </td></tr>
    <tr><td class="paramname">factor_matrices</td><td>The factor matrices used in the decomposition. </td></tr>
    <tr><td class="paramname">fit</td><td>Pointer to a double where the computed fit value will be stored. </td></tr>
    <tr><td class="paramname">error_T</td><td>The array to store the reconstruction error for each block. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
    <tr><td class="paramname">device_count</td><td>The number of CUDA devices available for computation. </td></tr>
    <tr><td class="paramname">cuda_agents</td><td>Array of CUDA agents managing device resources. </td></tr>
    <tr><td class="paramname">scheduler</td><td>The scheduler managing computational tasks. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1921d1d3aba84f518893f68814bca4ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1921d1d3aba84f518893f68814bca4ac">&#9670;&nbsp;</a></span>TuckerDecomposition()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TensorType , typename OptimizerType , typename CudaAgentType , typename SchedulerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::TuckerDecomposition </td>
          <td>(</td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OptimizerType *&#160;</td>
          <td class="paramname"><em>optimizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">CudaAgentType **&#160;</td>
          <td class="paramname"><em>cuda_agents</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">SchedulerType *&#160;</td>
          <td class="paramname"><em>scheduler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs Tucker decomposition on a tensor. </p>
<p>This function implements the Tucker decomposition algorithm for a given tensor. It initializes factor matrices and a core tensor, and iteratively updates them using CUDA-enabled operations. The decomposition is performed across multiple GPUs with the help of a scheduler and CUDA agents.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TensorType</td><td>The type of the tensor being decomposed. </td></tr>
    <tr><td class="paramname">OptimizerType</td><td>The type of optimizer used in the decomposition. </td></tr>
    <tr><td class="paramname">CudaAgentType</td><td>The type of CUDA agent managing GPU resources. </td></tr>
    <tr><td class="paramname">SchedulerType</td><td>The type of scheduler managing the decomposition tasks.</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Pointer to the input tensor to be decomposed. </td></tr>
    <tr><td class="paramname">optimizer</td><td>Pointer to the optimizer used for the decomposition. </td></tr>
    <tr><td class="paramname">cuda_agents</td><td>Array of pointers to CUDA agents managing the GPU resources. </td></tr>
    <tr><td class="paramname">scheduler</td><td>Pointer to the scheduler managing the decomposition tasks. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae8daca273725962464a8cd6bd421f683"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8daca273725962464a8cd6bd421f683">&#9670;&nbsp;</a></span>UpdateFactorMatrices()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TensorType , typename MatrixType , typename ValueType , typename CudaAgentType , typename SchedulerType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void supertensor::gputucker::UpdateFactorMatrices </td>
          <td>(</td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">TensorType *&#160;</td>
          <td class="paramname"><em>core_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType ***&#160;</td>
          <td class="paramname"><em>factor_matrices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueType **&#160;</td>
          <td class="paramname"><em>delta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType **&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MatrixType **&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rank</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>device_count</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">CudaAgentType **&#160;</td>
          <td class="paramname"><em>cuda_agents</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">SchedulerType *&#160;</td>
          <td class="paramname"><em>scheduler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Updates the factor matrices in Tucker decomposition. </p>
<p>This function updates the factor matrices used in Tucker decomposition by first computing the necessary matrices B and vectors C, and then using them to update each factor matrix. The updates are performed for each dimension of the tensor in a loop.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TensorType</td><td>The type of the tensor being decomposed. </td></tr>
    <tr><td class="paramname">MatrixType</td><td>The type used for matrices in the decomposition. </td></tr>
    <tr><td class="paramname">ValueType</td><td>The type used for values in the decomposition. </td></tr>
    <tr><td class="paramname">CudaAgentType</td><td>The type of CUDA agent managing GPU resources. </td></tr>
    <tr><td class="paramname">SchedulerType</td><td>The type of scheduler managing the decomposition tasks.</td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Pointer to the input tensor. </td></tr>
    <tr><td class="paramname">core_tensor</td><td>Pointer to the core tensor. </td></tr>
    <tr><td class="paramname">factor_matrices</td><td>Array of pointers to the factor matrices to be updated. </td></tr>
    <tr><td class="paramname">delta</td><td>Array of delta values used in the decomposition. </td></tr>
    <tr><td class="paramname">B</td><td>Array of matrices B computed during the update. </td></tr>
    <tr><td class="paramname">C</td><td>Array of vectors C computed during the update. </td></tr>
    <tr><td class="paramname">rank</td><td>The Tucker rank. </td></tr>
    <tr><td class="paramname">device_count</td><td>The number of devices available for computation. </td></tr>
    <tr><td class="paramname">cuda_agents</td><td>Array of pointers to CUDA agents managing the GPU resources. </td></tr>
    <tr><td class="paramname">scheduler</td><td>Pointer to the scheduler managing the decomposition tasks. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacesupertensor.html">supertensor</a></li><li class="navelem"><a class="el" href="namespacesupertensor_1_1gputucker.html">gputucker</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
